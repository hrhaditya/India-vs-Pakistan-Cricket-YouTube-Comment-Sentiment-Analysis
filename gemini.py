# -*- coding: utf-8 -*-
"""gemini.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A8xPTaEEeR92TTPzvDZIWh-2dDrx37hd
"""

import pandas as pd
import os
import re

dataPath = "/content/youtube_comments_progress(1).csv"
df = pd.read_csv(dataPath)
df = df.dropna(subset=['text'])

# Define a function to clean the text
def preprocess_comment(comment):
    # Remove URLs
    comment = re.sub(r'http\S+|www\S+|https\S+', '', comment, flags=re.MULTILINE)
    # Remove mentions and hashtags
    comment = re.sub(r'\@\w+|\#', '', comment)
    # Lowercase the text
    comment = comment.lower()
    comment = re.sub(r'[^\w\s,]', '', comment)
    # Remove special characters and digits
    comment = re.sub(r'\W', ' ', comment)
    comment = re.sub(r'\d', '', comment)
    # Remove extra spaces
    comment = re.sub(r'\s+', ' ', comment).strip()
    return comment

# Apply the preprocessing function to the comments column
df['cleaned_comments'] = df['text'].apply(preprocess_comment).copy()

# View the cleaned comments
print(df['cleaned_comments'])

import google.generativeai as genai

GOOGLE_API_KEY = "AIzaSyC6qVv8BdDxLB7gnFmhLEdaf8OPbEZa6Bc"
genai.configure(api_key=GOOGLE_API_KEY)

model = genai.GenerativeModel("models/gemini-1.5-pro-latest")

response = model.generate_content(
    "Classify the sentiment of this comment: 'India played brilliantly today!' Only respond: Positive, Neutral, or Negative"
)
print(response.text)

import time
import pandas as pd
from tqdm import tqdm  # progress bar

# Load dataset
df = pd.read_csv("youtube_comments_progress(1).csv")
df = df.dropna(subset=["text"])
df = df.reset_index(drop=True)

# Sample smaller set first for testing
df = df.sample(100).reset_index(drop=True)

# Add column to store results
df["gemini_sentiment"] = ""

# Define Gemini function with error handling
def classify_sentiment(comment):
    prompt = f"""
Classify the sentiment of this YouTube comment about a cricket match.
Respond with ONE word only: Positive, Neutral, or Negative.

Comment: "{comment}"
Sentiment:
"""
    try:
        response = model.generate_content(prompt)
        return response.text.strip().split("\n")[0]
    except Exception as e:
        print("Error:", e)
        return "Error"

# Process in batches to avoid overload
batch_size = 100
start_idx = 0
end_idx = len(df)

for i in tqdm(range(start_idx, end_idx)):
    if df.loc[i, "gemini_sentiment"] == "":
        df.loc[i, "gemini_sentiment"] = classify_sentiment(df.loc[i, "text"])
        time.sleep(1.5)  # delay between API calls

    # Save every 50 rows
    if i % 50 == 0:
        df.to_csv("gemini_sentiment_results_partial.csv", index=False)

# Final save
df.to_csv("gemini_sentiment_results_final.csv", index=False)
print("âœ… All done! File saved.")

def classify_sentiment(comment):
    prompt = f"""
Classify the sentiment of this YouTube comment about a cricket match.
Only respond with ONE word: Positive, Neutral, or Negative.

Comment: "{comment}"
Sentiment:
"""
    try:
        response = model.generate_content(prompt)
        return response.text.strip().split("\n")[0]
    except Exception as e:
        print(f"Error: {e}")
        return "Error"

try:
    df = pd.read_csv("gemini_sentiment_progress.csv")  # if exists
    print("Resuming from saved progress...")
except FileNotFoundError:
    df = pd.read_csv("youtube_comments_progress(1).csv")
    df = df.dropna(subset=["text"])
    df["gemini_sentiment"] = ""
    df.to_csv("gemini_sentiment_progress.csv", index=False)

import time
import pandas as pd
from tqdm import tqdm

df = pd.read_csv("/content/gemini_sentiment_results_full(5).csv")

# Safe loop with actual row indexes
for i in tqdm(df.index):
    if pd.isna(df.at[i, "gemini_sentiment"]) or df.at[i, "gemini_sentiment"].strip() == "":
        df.at[i, "gemini_sentiment"] = classify_sentiment(df.at[i, "text"])
        time.sleep(1.5)

    if i % 100 == 0:
        df.to_csv("gemini_sentiment_results_full.csv", index=False)  # save progress

# Final save
df.to_csv("gemini_sentiment_results_full.csv", index=False)