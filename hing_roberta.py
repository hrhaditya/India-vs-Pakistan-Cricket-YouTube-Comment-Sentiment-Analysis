# -*- coding: utf-8 -*-
"""hing-roberta.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XXhOmw4r3ubYwp0LD7B9dhJojYJ39-JM
"""

import pandas as pd
import os
import re

dataPath = "/content/youtube_comments_progress(1).csv"
df = pd.read_csv(dataPath)
df = df.dropna(subset=['text'])

# Define a function to clean the text
def preprocess_comment(comment):
    # Remove URLs
    comment = re.sub(r'http\S+|www\S+|https\S+', '', comment, flags=re.MULTILINE)
    # Remove mentions and hashtags
    comment = re.sub(r'\@\w+|\#', '', comment)
    # Lowercase the text
    comment = comment.lower()
    comment = re.sub(r'[^\w\s,]', '', comment)
    # Remove special characters and digits
    comment = re.sub(r'\W', ' ', comment)
    comment = re.sub(r'\d', '', comment)
    # Remove extra spaces
    comment = re.sub(r'\s+', ' ', comment).strip()
    return comment

# Apply the preprocessing function to the comments column
df['cleaned_comments'] = df['text'].apply(preprocess_comment).copy()

# View the cleaned comments
print(df['cleaned_comments'])

from transformers import AutoTokenizer, AutoModelForSequenceClassification

# Load the tokenizer and model
tokenizer = AutoTokenizer.from_pretrained("l3cube-pune/hing-roberta")
model = AutoModelForSequenceClassification.from_pretrained("l3cube-pune/hing-roberta")

# STEP 1: Install dependencies
!pip install -q transformers datasets evaluate scikit-learn

# STEP 2: Load and prepare dataset
import pandas as pd
import re
from sklearn.model_selection import train_test_split

# Load dataset
df = pd.read_csv("/content/youtube_comments_progress(1).csv")
df = df.dropna(subset=['text'])

# Clean text
def preprocess_comment(comment):
    comment = re.sub(r'http\S+|www\S+|https\S+', '', comment, flags=re.MULTILINE)
    comment = re.sub(r'\@\w+|\#', '', comment)
    comment = comment.lower()
    comment = re.sub(r'[^\w\s,]', '', comment)
    comment = re.sub(r'\W', ' ', comment)
    comment = re.sub(r'\d', '', comment)
    comment = re.sub(r'\s+', ' ', comment).strip()
    return comment

df['cleaned_comments'] = df['text'].apply(preprocess_comment)

# Check if 'gpt_sentiment' column exists
if 'gpt_sentiment' not in df.columns:
    print("⚠️ 'gpt_sentiment' column not found. Creating mock labels for demonstration...")
    df = df.sample(frac=1).reset_index(drop=True)
    # Create mock labels just for testing (rotate through classes)
    mock_labels = ['Positive', 'Neutral', 'Negative']
    df['gpt_sentiment'] = [mock_labels[i % 3] for i in range(len(df))]

# Map labels
label_map = {'Negative': 0, 'Neutral': 1, 'Positive': 2}
df = df[df['gpt_sentiment'].isin(label_map.keys())].copy()
df['label'] = df['gpt_sentiment'].map(label_map)

# Train/val split
train_texts, val_texts, train_labels, val_labels = train_test_split(
    df['cleaned_comments'].tolist(),
    df['label'].tolist(),
    test_size=0.1,
    random_state=42
)

# Step 1: Install Required Libraries
!pip install transformers -q
!pip install torch -q

# Step 2: Import Libraries
import pandas as pd
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
from torch.nn.functional import softmax
from tqdm import tqdm

# Step 3: Load Dataset
df = pd.read_csv("/content/youtube_comments_progress(1).csv")
df = df.dropna(subset=['text'])  # Adjust column name if it's different

# Step 4: Load Hing-RoBERTa model and tokenizer
model_name = "l3cube-pune/hing-roberta"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)
model.eval()  # set to evaluation mode

# Step 5: Inference function
def get_sentiment(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=128)
    with torch.no_grad():
        outputs = model(**inputs)
        probs = softmax(outputs.logits, dim=1)
        label = torch.argmax(probs, dim=1).item()
    return label  # 0: Negative, 1: Neutral, 2: Positive

# Step 6: Apply to dataset (can take time, so use tqdm)
tqdm.pandas()
df["hing_roberta_sentiment"] = df["text"].progress_apply(get_sentiment)

# Step 7: (Optional) Map Labels to Text
label_map = {0: "Negative", 1: "Neutral", 2: "Positive"}
df["hing_roberta_sentiment_label"] = df["hing_roberta_sentiment"].map(label_map)

# Step 8: Save the results
df.to_csv("hing_roberta_sentiment_output.csv", index=False)

